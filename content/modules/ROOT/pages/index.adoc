= ChatOps generative AI with LLM, RAG and data science pipelines

Welcome to this demonstration of how Red Hat OpenShift AI enables businesses to build sophisticated AI-powered chatbots using large language models (LLMs) and retrieval-augmented generation (RAG).

== About This Demo

This demonstration explores how to leverage the power of LLMs with RAG within the Red Hat OpenShift AI environment. You'll see how businesses can:

* Build chatbots that answer complex questions with company-specific knowledge
* Enhance customer interactions with accurate, context-aware responses
* Streamline operations through automated knowledge management
* Deploy enterprise-grade AI without expensive model retraining

**Key Insight:** Traditional LLMs lack knowledge about your company's products, services, and internal documentation. RAG solves this by augmenting LLMs with your proprietary knowledge base—without the cost and complexity of model retraining.

== What You'll Learn

**Business Value:**

* How RAG reduces AI deployment costs by 10× compared to model retraining
* Why organizations achieve 70% reduction in support escalations with RAG
* The business case for enterprise AI platforms vs point solutions
* ROI timelines and success metrics for RAG deployments

**Technical Capabilities:**

* RAG architecture: indexing, retrieval, and generation workflows
* OpenShift AI platform features for building production AI applications
* Automated data science pipelines for knowledge base updates
* Developer workflows using Jupyter notebooks and visual pipeline editors

**Demo Highlights:**

* Live demonstration of RAG chatbot with company-specific knowledge
* Automated pipeline for ingesting documentation and validating quality
* Two workflows: admin (infrastructure as code) and data scientist (visual editor)
* Production-ready monitoring, GitOps automation, and troubleshooting

== Demo Structure

This demo is organized into 5 modules using the **Know/Show** structure designed for presenter-led demonstrations:

**Module 1: Overview** (5-10 minutes)

* Business challenges with generic LLMs
* How RAG solves the knowledge gap
* Value proposition and ROI summary

**Module 2: Technical Background** (10-15 minutes)

* Deep dive into RAG architecture
* OpenShift AI platform capabilities
* Integration with enterprise workflows

**Module 3: Demo Part 1 - Understanding RAG** (15-20 minutes)

* Visual explanation of RAG components
* Business impact of retrieval-augmented generation
* Preparation for live demonstration

**Module 4: Demo Part 2 - Live Demonstration** (30-40 minutes)

* Environment validation and setup
* Automated RAG pipelines (admin and data scientist workflows)
* Quality validation and monitoring
* Troubleshooting guidance

**Module 5: Conclusion and Next Steps** (10-15 minutes)

* Business impact recap and ROI analysis
* Customer success path (POC → pilot → production)
* Q&A and follow-up resources

**Total demo time:** 70-100 minutes (adjust based on audience depth)

== Know/Show Structure

This demo uses the **Know/Show** methodology:

**Know Sections:**

* Business context and challenges
* Value propositions and benefits
* Strategic insights for decision makers
* Why this technology matters

**Show Sections:**

* Step-by-step presenter instructions
* What to demonstrate and how
* Expected outcomes and key talking points
* Handling questions and objections

**Benefits of This Approach:**

* Presenters understand business value before demonstrating features
* Consistent messaging across different presenters
* Flexibility to adjust depth based on audience
* Clear separation of business context from technical steps

== Target Audiences

This demo is designed for multiple audiences:

**Technical Managers:**

* Focus on: Platform capabilities, developer productivity, integration
* Emphasize: Self-service workflows, automated operations, enterprise governance

**C-Level Executives:**

* Focus on: Business outcomes, ROI, competitive advantage
* Emphasize: Cost savings, time-to-value, risk mitigation

**Data Scientists:**

* Focus on: Development workflows, model serving, pipeline automation
* Emphasize: Familiar tools (Jupyter, Python), no Kubernetes expertise required

**Platform Engineers:**

* Focus on: Infrastructure, scalability, GitOps automation
* Emphasize: OpenShift integration, monitoring, troubleshooting

== Prerequisites

**For Presenters:**

* Access to pre-deployed RAG environment on OpenShift
* Basic understanding of AI/ML concepts (LLMs, embeddings, vector databases)
* Familiarity with OpenShift console and OpenShift AI dashboard
* Review of all demo modules before presenting

**For Audience:**

* No technical prerequisites required
* Basic understanding of AI chatbots helpful but not required
* Interest in enterprise AI deployment and operations

== Getting Started

**If you're a presenter:**

. Review xref:01-overview.adoc[Module 1: Overview] for business context
. Read through xref:04-module-02-demo.adoc[Module 4: Live Demonstration] for technical steps
. Practice the demo flow in a test environment
. Customize talking points based on your audience

**If you're evaluating this demo for your organization:**

. Start with xref:01-overview.adoc[Module 1: Overview] to understand the business value
. Review xref:02-details.adoc[Module 2: Technical Background] for architecture details
. Watch the live demonstration (or request a custom demo from Red Hat)
. See xref:05-conclusion.adoc[Module 5: Conclusion] for next steps and resources

== Demo Environment

**What's Included:**

* **OpenShift cluster**: Enterprise Kubernetes platform
* **OpenShift AI**: Complete AI/ML platform with Jupyter, pipelines, and model serving
* **RAG components**:
  * PostgreSQL with pgvector extension (vector database)
  * LLM model serving (Granite, Mistral, or CodeLlama)
  * Gradio chatbot interface
  * MinIO S3-compatible storage
* **Automation**: Argo CD for GitOps, Tekton for pipelines
* **Sample data**: Red Hat OpenShift AI documentation for testing

**Access Information:**

Demo credentials and URLs are provided by your Red Hat account team or found in the "Advanced settings" section of your deployed service on demo.redhat.com.

== Quick Links

**Jump to Key Sections:**

* xref:01-overview.adoc#common-customer-questions[Common Customer Questions]
* xref:03-module-01-intro.adoc#part-3-business-impact-real-world-benefits[Business Benefits of RAG]
* xref:04-module-02-demo.adoc#part-3-automated-rag-pipelines-admin-persona[Automated RAG Pipelines Demo]
* xref:04-module-02-demo.adoc#troubleshooting[Troubleshooting Guide]
* xref:05-conclusion.adoc#next-steps-for-your-organization[Next Steps and Resources]

**External Resources:**

* link:https://access.redhat.com/documentation/en-us/red_hat_openshift_ai_self-managed/2.9^[Red Hat OpenShift AI Documentation^]
* link:https://github.com/ritzshah/llm-rag-deployment^[Demo Source Code Repository^]
* link:https://developers.redhat.com/topics/ai-ml^[Red Hat Developer - AI/ML Resources^]

== Support and Feedback

**Need Help?**

* **Technical issues**: Contact your Red Hat support team
* **Demo questions**: Reach out to your Red Hat account manager
* **Content feedback**: Submit issues to the demo repository

**Contributing:**

This demo is continuously improved based on presenter and customer feedback. If you have suggestions for improvements, please share them with the Red Hat demo team.

---

**Ready to get started?** Proceed to xref:01-overview.adoc[Module 1: Overview] to begin the demonstration.
